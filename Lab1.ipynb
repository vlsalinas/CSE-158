{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import svm\n",
    "import ast\n",
    "\n",
    "#import patsy\n",
    "#import statsmodels.api as sm\n",
    "#import scipy.stats as stats\n",
    "#from scipy.stats import ttest_ind, chisquare, normaltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "def parseData(fname):\n",
    "\tfor l in urllib.request.urlopen(fname):\n",
    "\t\tyield eval(l)\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse258/data/beer/beer_50000.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################################################################        \n",
    "######                     QUESTION 1                           \n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1 = []\n",
    "one_star_ratings = 0\n",
    "two_star_ratings = 0\n",
    "three_star_ratings = 0\n",
    "four_star_ratings = 0\n",
    "five_star_ratings = 0\n",
    "\n",
    "for i in data:\n",
    "    for x,y in i.items():\n",
    "        if x == \"review/taste\":\n",
    "            lst1.append(y)\n",
    "            \n",
    "for i in lst1:\n",
    "    if i >= 1.0 and i < 2.0:\n",
    "        one_star_ratings = one_star_ratings + 1\n",
    "    elif i >= 2.0 and i < 3.0:\n",
    "        two_star_ratings = two_star_ratings + 1\n",
    "    elif i >= 3.0 and i < 4.0:\n",
    "        three_star_ratings = three_star_ratings + 1\n",
    "    elif i >= 4.0 and i < 5.0:\n",
    "        four_star_ratings = four_star_ratings + 1\n",
    "    elif i >= 5.0:\n",
    "        five_star_ratings = five_star_ratings + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of one star ratings: 554\n",
      "# of two star ratings: 2723\n",
      "# of three star ratings: 12934\n",
      "# of four star ratings: 29458\n",
      "# of five star ratings: 4331\n"
     ]
    }
   ],
   "source": [
    "print(\"# of one star ratings: %s\" % one_star_ratings)  # of 1 star ratings = 201\n",
    "print(\"# of two star ratings: %s\" % two_star_ratings)  # of 2 star ratings = 1099\n",
    "print(\"# of three star ratings: %s\" % three_star_ratings)  # of 3 star ratings = 4137\n",
    "print(\"# of four star ratings: %s\" % four_star_ratings)  # of 3 star ratings = 4137\n",
    "print(\"# of five star ratings: %s\" % five_star_ratings)  # of 3 star ratings = 4137"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################################################################        \n",
    "######                      QUESTION 2                           #\n",
    "#######################################################################        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all beers (including mulitple occurances) into a list\n",
    "\n",
    "list_of_all_beers = [d['beer/name'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out all beers including multiple occurances\n",
    "\n",
    "#list_of_all_beers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_all_beers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list = set(list_of_all_beers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1872"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "beers_unique = [[x,list_of_all_beers.count(x)] for x in set(list_of_all_beers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beers_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1872"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(beers_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of all beers with at least 5 reviews (unique)\n",
    "\n",
    "list6 = []\n",
    "list7 = []\n",
    "for i in beers_unique:\n",
    "    if i[1] >= 5:\n",
    "        list6.append(i[0])\n",
    "        list7.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647\n",
      "647\n"
     ]
    }
   ],
   "source": [
    "print(len(list6))\n",
    "print(len(list7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all beers with at least 5 reviews\n",
    "\n",
    "at_least_5 = list(zip(list6, list7))\n",
    "#at_least_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of all beers and their review/taste\n",
    "\n",
    "list1 = []\n",
    "list2 = []\n",
    "for i in data:\n",
    "    for a,b in i.items():\n",
    "        for c,d in i.items():\n",
    "            if a == 'beer/name':\n",
    "                if c == 'review/taste':\n",
    "                    list1.append(b)\n",
    "                    list2.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(list1))\n",
    "print(len(list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_name_taste = list(zip(list1, list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beer_name_taste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(beer_name_taste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "list3 = []\n",
    "list4 = []\n",
    "for a,b in diction1.items():\n",
    "    count = 0\n",
    "    for c in beer_name_taste:\n",
    "        if c[0] == a:\n",
    "            count += c[1]\n",
    "    list3.append(a)\n",
    "    list4.append(count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647\n",
      "647\n"
     ]
    }
   ],
   "source": [
    "print(len(list3))\n",
    "print(len(list4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of beers with all their reviews/taste ratings added together\n",
    "\n",
    "combined = list(zip(list3, list4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "list8 = []\n",
    "list9 = []\n",
    "for i in at_least_5:\n",
    "    for j in combined:\n",
    "        if j[0] == i[0]:\n",
    "            list8.append(i[0])\n",
    "            list9.append(j[1] / i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647\n",
      "647\n"
     ]
    }
   ],
   "source": [
    "print(len(list8))\n",
    "print(len(list9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averages\n",
    "avg = list(zip(list8, list9))\n",
    "#avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6970172684458396"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Higest averages\n",
    "maximum = 0\n",
    "for i in avg:\n",
    "    if i[1] >= maximum:\n",
    "        maximum = i[1]\n",
    "maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founders CBS Imperial Stout']"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find if other beers also have same highest rating for review/taste\n",
    "list11 = []\n",
    "for i in avg:\n",
    "    if i[1] == maximum:\n",
    "        list11.append(i[0])\n",
    "list11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest average rated beer (review/taste): Founders CBS Imperial Stout\n",
      "Highest average: 4.6970172684458396\n"
     ]
    }
   ],
   "source": [
    "# Print out highest average rated beer and its average\n",
    "print(\"Highest average rated beer (review/taste): %s\" % list11[0])\n",
    "print(\"Highest average: %s\" % maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst3 = []\n",
    "for i in range(len(data)):\n",
    "    lst3.append(1)\n",
    "    \n",
    "len(lst3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst4 = []\n",
    "\n",
    "for i in data:\n",
    "    for x,y in i.items():\n",
    "        if x == 'beer/style':\n",
    "            lst4.append(y)\n",
    "\n",
    "#lst4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "618"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst6 = []\n",
    "for i in lst4:\n",
    "    if i == 'Hefeweizen':\n",
    "        lst6.append(1)\n",
    "    else:\n",
    "        lst6.append(0)\n",
    "        \n",
    "lst6.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst5 = []\n",
    "for i in data:\n",
    "    for x,y in i.items():\n",
    "        if x == 'beer/ABV':\n",
    "            lst5.append(y)\n",
    "     \n",
    "    \n",
    "#lst5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(zip(lst3,lst6,lst5))\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [d['review/taste'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "theta,residuals,rank,s = np.linalg.lstsq(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################################################################        \n",
    "                     QUESTION 3            \n",
    "#######################################################################\n",
    "\n",
    "\n",
    "\n",
    "theta_0 = indicates the average review/taste. <br>\n",
    "theta_1 = indicates the difference between the average review/taste when beer/ABV is 0. <br>\n",
    "theta_2 = indicates the difference between the average review/taste when beer is not Hefeweizen (0).  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_0: 3.1179508424741784\n",
      "theta_1: -0.05637405770379309\n",
      "theta_2: 0.10877901639208253\n"
     ]
    }
   ],
   "source": [
    "# Theta values for theta 0, theta 1, and theta 2\n",
    "print(\"theta_0: %s\" % theta[0])\n",
    "print(\"theta_1: %s\" % theta[1])\n",
    "print(\"theta_2: %s\" % theta[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################################################\n",
    "<br>                           Question 4 \n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the original dataset in half\n",
    "data_1 = data[:len(data)//2] # training set\n",
    "data_2 = data[len(data)//2:] # test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_1(d):\n",
    "    temp_lst1 = []\n",
    "    \n",
    "    for i in range(len(d)):\n",
    "        temp_lst1.append(1)\n",
    "        \n",
    "    return temp_lst1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_2(d):\n",
    "    temp_lst = []\n",
    "\n",
    "    for i in d:\n",
    "        for x,y in i.items():\n",
    "            if x == 'beer/style':\n",
    "                temp_lst.append(y)\n",
    "\n",
    "    temp_lst2 = []\n",
    "    for i in temp_lst:\n",
    "        if i == 'Hefeweizen':\n",
    "            temp_lst2.append(1)\n",
    "        else:\n",
    "            temp_lst2.append(0)\n",
    "    \n",
    "    return temp_lst2\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_3(d):\n",
    "    temp_lst = []\n",
    "    \n",
    "    for i in d:\n",
    "        for x,y in i.items():\n",
    "            if x == 'beer/ABV':\n",
    "                temp_lst.append(y)\n",
    "     \n",
    "    return temp_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X(d):\n",
    "    \n",
    "    X = list(zip(get_col_1(d), get_col_2(d), get_col_3(d)))\n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(d):\n",
    "    \n",
    "    y = [da['review/taste'] for da in d]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thetas(d):\n",
    "    \n",
    "    X = get_X(d)\n",
    "    y = get_y(d)\n",
    "    \n",
    "    theta,residuals,rank,s = np.linalg.lstsq(X, y)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.11795084, -0.05637406,  0.10877902])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify get functions work on original data\n",
    "a = get_thetas(data)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.11795084, -0.05637406,  0.10877902])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MSE(ratings, predictions):\n",
    "    \n",
    "    mse = 0\n",
    "    \n",
    "    for r, p in zip(ratings, predictions):\n",
    "        mse = mse + (r - p)**2\n",
    "        \n",
    "    return (mse / len(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings(d):\n",
    "    tmp_lst = []\n",
    "    \n",
    "    for i in d:\n",
    "        for x,y in i.items():\n",
    "            if x == 'review/taste':\n",
    "                tmp_lst.append(y)\n",
    "                \n",
    "    return tmp_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = get_X(data_1)\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_new_model(th, d):\n",
    "    \n",
    "    # remember: th[0] =  3.11795084\n",
    "    #           th[1] = -0.05637406\n",
    "    #           th[2] =  0.10877902\n",
    "    \n",
    "    temp = []\n",
    "    \n",
    "    X = get_X(d)\n",
    "    \n",
    "    for x in X:\n",
    "        result = 0\n",
    "        result = th[0] + th[1]*x[1] + th[2]*x[2]\n",
    "        temp.append(result)\n",
    "        \n",
    "    return temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06477346])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings = apply_new_model(a, data_1)\n",
    "train_predictions = np.full((len(train_ratings),1),np.mean(train_ratings))\n",
    "\n",
    "train_MSE = get_MSE(train_ratings, train_predictions)\n",
    "train_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05888718])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings = apply_new_model(a, data_2)\n",
    "test_predictions = np.full((len(test_ratings),1),np.mean(test_ratings))\n",
    "\n",
    "test_MSE = get_MSE(test_ratings, test_predictions)\n",
    "test_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set MSE: [0.06477346]\n",
      "Test set MSE: [0.05888718]\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "#               ANSWER FOR QUESTION 4                 #\n",
    "################################################################\n",
    "\n",
    "print(\"Training set MSE: %s\" % train_MSE)\n",
    "print(\"Test set MSE: %s\" % test_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################### <br>\n",
    "                           Question 5 <br>#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the contents of the original dataset into a new dataset\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the new dataset in half\n",
    "shuffled_1 = data[:len(data)//2]\n",
    "shuffled_2 = data[len(data)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0619843])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get MSE for new training set\n",
    "\n",
    "shuffled_1_ratings = apply_new_model(a, shuffled_1)\n",
    "shuffled_1_predictions = np.full((len(shuffled_1_ratings),1),np.mean(shuffled_1_ratings))\n",
    "\n",
    "shuffled_1_MSE = get_MSE(shuffled_1_ratings, shuffled_1_predictions)\n",
    "shuffled_1_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06583642])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get MSE for new test set\n",
    "\n",
    "shuffled_2_ratings = apply_new_model(a, shuffled_2)\n",
    "shuffled_2_predictions = np.full((len(shuffled_2_ratings),1),np.mean(shuffled_2_ratings))\n",
    "\n",
    "shuffled_2_MSE = get_MSE(shuffled_2_ratings, shuffled_2_predictions)\n",
    "shuffled_2_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set MSE: [0.0619843]\n",
      "Test set MSE: [0.06583642]\n"
     ]
    }
   ],
   "source": [
    "# Display training and test MSE\n",
    "\n",
    "print(\"Training set MSE: %s\" % shuffled_1_MSE)\n",
    "print(\"Test set MSE: %s\" % shuffled_2_MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################### <br>\n",
    "                           Question 6 <br>#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle dataset once more\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all features into separate lists to combine next\n",
    "review_taste = [d['review/taste'] for d in data]\n",
    "review_app = [d['review/appearance'] for d in data]\n",
    "review_ar = [d['review/aroma'] for d in data]\n",
    "review_pa = [d['review/palate'] for d in data]\n",
    "review_overall = [d['review/overall'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all lists into one in order: taste, appearance, aroma, palate, overall\n",
    "\n",
    "X = []\n",
    "X = list(zip(review_taste, review_app, review_ar, review_pa, review_overall))\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels for if beer/style is Hefeweizen\n",
    "\n",
    "y = [\"Hefeweizen\" in d['beer/style'] for d in data]\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test set again\n",
    "X_train = X[:len(X)//2]\n",
    "y_train = y[:len(y)//2]\n",
    "\n",
    "X_test = X[len(X)//2:]\n",
    "y_test = y[len(y)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "clf = svm.SVC(C=1000, kernel='linear')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display train_predictions\n",
    "train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display test_predictions\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctness\n",
    "correct_train = (train_predictions == y_train)\n",
    "correct_test = (test_predictions == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "trainAcc = sum(correct_train) / len(correct_train)\n",
    "testAcc = sum(correct_test) / len(correct_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.98732\n",
      "Test accuracy: 0.98796\n"
     ]
    }
   ],
   "source": [
    "# Answer to question 6\n",
    "\n",
    "print(\"Training accuracy: %s\" % trainAcc)\n",
    "print(\"Test accuracy: %s\" % testAcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################### <br>\n",
    "                           Question 7 <br>#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle dataset once more\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all features into separate lists to combine next\n",
    "review_taste = [d['review/taste'] for d in data]\n",
    "review_app = [d['review/appearance'] for d in data]\n",
    "review_aroma = [d['review/aroma'] for d in data]\n",
    "beer_ABV = [d['beer/ABV'] for d in data]\n",
    "review_overall = [d['review/overall'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all lists into one in order: taste, appearance, aroma, palate, overall\n",
    "\n",
    "my_X = []\n",
    "my_X = list(zip(review_taste, review_app, review_aroma, beer_ABV, review_overall))\n",
    "#my_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels for if beer/style is Hefeweizen\n",
    "\n",
    "my_y = [\"Hefeweizen\" in d['beer/style'] for d in data]\n",
    "#my_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test set again\n",
    "my_X_train = my_X[:len(X)//2]\n",
    "my_y_train = my_y[:len(y)//2]\n",
    "\n",
    "my_X_test = my_X[len(X)//2:]\n",
    "my_y_test = my_y[len(y)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "clf = svm.SVC(C=1000, kernel='linear')\n",
    "clf.fit(my_X_train, my_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train_predictions = clf.predict(my_X_train)\n",
    "my_test_predictions = clf.predict(my_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display train_predictions\n",
    "my_train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display test_predictions\n",
    "my_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctness\n",
    "my_correct_train = (my_train_predictions == my_y_train)\n",
    "my_correct_test = (my_test_predictions == my_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "myTrainAcc = sum(my_correct_train) / len(my_correct_train)\n",
    "myTestAcc = sum(my_correct_test) / len(my_correct_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.98764\n",
      "Test accuracy: 0.98764\n"
     ]
    }
   ],
   "source": [
    "# Display accuracies for training and test sets\n",
    "print(\"Training accuracy: %s\" % myTrainAcc)\n",
    "print(\"Test accuracy: %s\" % myTestAcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################### <br>\n",
    "                           Question 8 <br>#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy for different values of \"c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for SVM\n",
    "def get_accuracy(c):\n",
    "    clf = svm.SVC(C=c, kernel='linear')\n",
    "    clf.fit(my_X_train, my_y_train)\n",
    "    \n",
    "    my_train_predictions = clf.predict(my_X_train)\n",
    "    my_test_predictions = clf.predict(my_X_test)\n",
    "    \n",
    "    \n",
    "    # Correctness\n",
    "    my_correct_train = (my_train_predictions == my_y_train)\n",
    "    my_correct_test = (my_test_predictions == my_y_test)\n",
    "    \n",
    "    # Accuracy\n",
    "    myTrainAcc = sum(my_correct_train) / len(my_correct_train)\n",
    "    myTestAcc = sum(my_correct_test) / len(my_correct_test)\n",
    "    \n",
    "    # Display accuracies for training and test sets\n",
    "    print(\"Training accuracy: %s\" % myTrainAcc)\n",
    "    print(\"Test accuracy: %s\" % myTestAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.98764\n",
      "Test accuracy: 0.98764\n"
     ]
    }
   ],
   "source": [
    "# c = 0.1\n",
    "get_accuracy(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.98764\n",
      "Test accuracy: 0.98764\n"
     ]
    }
   ],
   "source": [
    "# c = 10\n",
    "get_accuracy(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.98764\n",
      "Test accuracy: 0.98764\n"
     ]
    }
   ],
   "source": [
    "# c = 1000\n",
    "get_accuracy(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.98764\n",
      "Test accuracy: 0.98764\n"
     ]
    }
   ],
   "source": [
    "# c = 10,000\n",
    "get_accuracy(10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
